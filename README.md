ğŸ¤ Audio Emotion Detection using Machine Learning

This project is a voice-based emotion recognition system built from scratch using Python. It classifies emotions (like happy, sad, angry, etc.) from audio recordings using MFCC features and a Random Forest Classifier, without relying on any pretrained models.
ğŸ“Œ Features

    ğŸ”Š Custom Audio Training â€“ Model is trained using your own voice samples.

    ğŸ¯ Emotion Classification â€“ Detects basic emotions (e.g., happy, sad, angry).

    ğŸ§  No Pretrained Model Used â€“ Everything is built and trained from scratch.

    ğŸ“ˆ Exportable Model â€“ Trained model is saved for future predictions using joblib.

ğŸ› ï¸ Technologies Used

    Python

    scikit-learn â€“ ML model training and evaluation

    librosa â€“ Audio feature extraction (MFCC)

    NumPy & Pandas â€“ Data handling

    joblib â€“ Model serialization

    Jupyter Notebook â€“ Experimentation and visualization

ğŸ“ Folder Structure

ğŸ“¦audio-emotion-detector
 â”£ ğŸ“‚ recordings/           # Raw audio files (.wav)
 â”£ ğŸ“‚ extracted_features/   # Extracted MFCC features
 â”£ ğŸ“œ emotion_model.pkl     # Exported trained model
 â”£ ğŸ“œ train.py              # Script to train the model
 â”£ ğŸ“œ predict.py            # Predict emotion from a new audio
 â”£ ğŸ“œ utils.py              # Helper functions
 â”— ğŸ“œ README.md             # Project documentation

ğŸ§ª How It Works

    Record voice samples labeled with emotions (e.g., "happy_1.wav", "sad_1.wav").

    Extract MFCC features from each audio using librosa.

    Train a Random Forest Classifier using scikit-learn.

    Save the trained model using joblib.

    Predict emotion from new voice inputs using the saved model.

â–¶ï¸ Run the Project
1. Install dependencies

pip install numpy pandas librosa scikit-learn joblib

2. Record or add .wav audio files to /recordings/ folder.
3. Train the model

python train.py

4. Predict emotion from a new voice sample

python predict.py your_audio_file.wav

ğŸ“Š Sample Emotions (can be customized)

    Happy

    Sad

    Angry

    Neutral

    You can expand the dataset with your own voice samples and labels.

ğŸ’¡ Learning Highlights

    Hands-on experience with audio signal processing

    Understanding MFCC and how voice can be converted into numerical features

    End-to-end supervised ML pipeline

    Model export and prediction without external tools

ğŸ§  Future Improvements

    Add more emotion categories

    Integrate deep learning models (like CNN or LSTM)

    Build a simple web interface for real-time predictions

ğŸ‘¨â€ğŸ’» Author

Mukul Mehra
Email: mukulmehra681@gmail.com
GitHub: muks79
